# Optimizing an ML Pipeline in Azure

## Overview

In this project, I had the opportunity to create and optimize an Azure ML pipeline. I have been provided a custom-coded modelâ€”a standard Scikit-learn Logistic Regression--which  hyperparameters I optimized using HyperDrive. I also used AutoML to build and optimize a model on the same dataset, so that I can compare the results of the two methods.

You can see the main steps that I have taken in the diagram below:

![image](creating-and-optimizing-an-ml-pipeline.png)

## Summary
The dataset used in this project is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to assess if the product (bank term deposit) would be ('yes') or not ('no') subscribed which is what we are predicting in this project.

So the aim of the project is to classify if a potential prospect would subcribe to the bank's term deposit. 

The best model found was using AutoMl experiment run. With AutoMl we have achieved classification prediction accuracy of 91.8% with VotingEnsemble model. 

## Scikit-learn Pipeline
The pipeline consists of a custom-coded Scikit-learn model logistic regression model stored in train.py script and a Hyperdrive run sweeping over model paramters. The following steps are part of the pipeline:
- Data cleaning and converting categorical data into one hot encoded data
- Splitting data into train and test sets
- Setting logistic regression parameters: 
    - --C - Inverse of regularization strenght 
    - --max_iter - Maximum number of iterations convergence
- Azure Cloud resources configuration
- Creating a HyperDrive configuration using the estimator, hyperparameter sampler, and policy
- Retrieve the best run and save the model from that run


**RandomParameterSampling**
Defines random sampling over a hyperparameter search space. In this sampling algorithm, parameter values are chosen from a set of discrete values or a distribution over a continuous range. This has an advantage against GridSearch method that runs all combinations of parameters and requires large amount of time to run.

For the Inverse of regularization strenght parameter I have chosen uniform distribution with min=0.001 and max=1.0 
For the Maximum number of iterations convergence I inputed a range of values (5, 25, 50, 100, 150)

The best model given by HyperDrive has the following parameters:
- --C = 0.3016
- --max_iter = 50



**What are the benefits of the early stopping policy you chose?**

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
